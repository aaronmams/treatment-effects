---
title: "Regression Discontinuity Design Tutorial"
output: html_notebook
---

# Introduction

In this exercise we are going to look at some data on schooling outcomes and early childhood intervention.  The data we will use come from two randomized experiments on early childhood intervention (The Carolina Aberdecian Project and Carolina Approach to Responsive Education).  Participants in the study were randomly selected to receive one or more educational treatments.  The study was pretty interesting and definitely worth reading more about...but a lengthy background is probably unnecessary here.

This exercise is focused on estimating the effect of early childhood interventions on educational outcomes.  Specifically, we will focus on the treatment variable *dc_trt* which indicates whether the subject was chosen to receive the Day Care Treatment.  

## Empirical strategy

The Abecedarian and CARE projects were randomized expiraments. We are going to artifically create a non-randomized trial in order to apply Regression Discontinuity Methods.  We are going to suppose that children with mother's having an IQ below 85 (the median IQ in the data sample) were selected to receive free daycare.  Children in the sample with mother's having an IQ of 85 or above did not receive the treatment.

This mirrors how many social programs work.  In education it seems sensible to try and identify children who may be disadvantaged in the educational system and implement some strategy to counter-act this.  The empirical challenge that this creates is that, since the treatment is non-randomly assigned, it can be difficult to estimate the marginal impact of the intervention.  Regression Discontinuity Designs are one approach for estimating average treatment effects when treatments are non-randomly assigned.

Where practical implementation is concerned, there is a really cool paper by Thoemmes, Liao, and Jin (2017) that uses the Abecedarian Project data and CARE data to illustrate use of RDD tools in R.  This R Notebook will use that paper as a guide and try to reproduce much of the analysis in Thoemmes, Liao, and Jin (2017). 


## R Prerequisites

* data manipulatin with dplyr
* data visualization with ggplot2
* linear models (OLS regression) in R with the lm() function

## R Skills

* data manipulation with memisc
* smoothing with Lowess (local polynomial regression)
* McCrary discontinuity tests with the rdd package
* estimation of RDD models with the rdd and rdtools packages

## Analytical Skills

* basic comfort with regression discontinuity designs
* estimation of local average treatment effects with RDDs
* McCrary test for continuity of assignment variable

## Examining the data

The data for this exercise comes from a panel data study of early childhood interventions: *The Carolina Abecedarian Project and the Carolina Approach to Responsive Education (CARE), 1972-1992*.  Details on this study as well as data files can be found [here](https://www.icpsr.umich.edu/icpsrweb/ICPSR/studies/4091).  


### Reading the data into R

I have stored the primary data file in this project directory. If you have cloned the GitHub repository then the data file is already stored in the 'RDD_data' subdirectory of the 'data' directory.  

The data are available as an SPSS portable file (.por).  I use the *memisc* package in R to read this file format.

```{r}
library(memisc)
library(dplyr)
library(ggplot2)

RDD.df <- tbl_df(as.data.frame(as.data.set(spss.portable.file('data/RDD_data/04091-0001-Data.por'))))
dim(RDD.df)
RDD.df

#trivial change for illustration
```

### Structure of the data

These data have 176 observations of 119 variable.  Each row in the data frame is an individual and columns contain individual specific information, intervention/treatment status, and observed outcomes.  

### Exploring treatment status

According to the codebook, there were a menu of possible interventions:

*The Abecedarian study randomized subjects into DAYCARE TREATMENT (treatment versus control) and SCHOOLAGE TREATMENT (treatment, control, and not assigned: subjects left study before receiving an assignment). These two factors are crossed, forming six groups in all. No Abecedarian subjects received Home Visits, so HV_TRT is always "0".*

*The CARE study randomized subjects into three groups: DAYCARE TREATMENT plus HOME VISIT TREATMENT plus SCHOOLAGE TREATMENT, HOME VISIT TREATMENT plus SCHOOLAGE TREAMENT, and CONTROL (no treatment of any kind).*

Let's examine how many units are in each treatment group:

```{r}
RDD.df %>% group_by(study,dc_trt,sa_trt,hv_trt) %>% summarise(count=n()) 

```

My take away from this is that there are 111 total study subjects and 6 possible groupings in the *Abecedarian* study:

* 23 of those did not receive either treatment (Day Care Treatment or Schoolage Treatment)
* 25 subject received both treatments
* 48 received at least 1 but not both treatments

There are 65 study subjects distributed among 3 groups in the CARE study:

* 23 subjects received no treatment of any kind
* 26 received only the Schoolage Treatment and the Home Visit Treatment
* 16 received all 3 possible treatments

### Exploring Covariates

There are 119 variables in this data set...far too many to explore individually.  Here we will take a quick look at distributions for a few of the more notable covariates:

* Gender
* Mother's Age
* Mother's WAIS score at time of subject's birth (Mom's IQ)
* Standford - Binet IQ score at 24, 36, adn 48 months.

```{r}

ggplot(RDD.df,aes(x=momsage)) + geom_bar()
ggplot(RDD.df,aes(x=momwais0)) + geom_density()
ggplot(RDD.df,aes(x=momwais0,y=sbiq24)) + geom_point() + geom_smooth() + theme_bw() +
   xlab("Mom's IQ") + ylab("Subject IQ at 24 months")
```


# Analytical Example: Regression Discontinuity Design

## Preliminary data manipulation and visualization

We simulate an RDD by supposing that selection into the treatment groups was done based on a threshold value of mother's IQ.  That is, we suppose that the treatments were assigned to mothers with IQ scores below the median score of the sample.  

```{r}
RDD.sim <- RDD.df %>% filter(
                (momwais0 >= median(momwais0) & dc_trt=='Control') |
                  (momwais0 < median(momwais0) & dc_trt=='Treatment'),!is.na(sbiq48))
RDD.sim
```


This is a "sharp RDD."  Let's take a look at an overly simplified way of evaluating the treatment effect: a local smoothing trend.  

```{r}
ggplot(RDD.df,aes(x=momwais0,y=sbiq48,group=dc_trt,color=dc_trt,shape=dc_trt)) + geom_point() + 
  geom_point(size = 2) +
  geom_smooth(method = "loess",
             formula = y ~ x,
             aes(linetype = dc_trt)) + theme_bw() + ylab("Child IQ at age 2") +
             xlab("Mother’s IQ\n\n(a)") +
             xlim(c(60, 110)) + ylim(c(60, 130)) +
             scale_colour_manual(values = c("darkgrey", "black")) +
             theme(legend.position = "none")

ggplot(RDD.sim) +
  aes(
     x = momwais0,
     y = sbiq48,
     group = dc_trt,
     color = dc_trt,
     shape = dc_trt
  ) +
geom_point(size = 2) +
geom_smooth(method = "loess",
            formula = y ~ x,
            aes(linetype = dc_trt)) + theme_bw() + ylab("Child IQ at age 2") +
            xlab("Mother’s IQ\n\n(b)") + xlim(c(60, 110)) + ylim(c(60, 130)) +
            scale_colour_manual(values = c("darkgrey", "black")) +
            theme(legend.title = element_blank()) +
            scale_shape_discrete(
    name = "DC_TRT",
    breaks = c("0", "1"),
    labels = c("Treatment", "Control")
  )

```


The sharp RDD is evident in the 2nd plot where all subjects with Mother's with an IQ score below 85 get the treatment and all subjects with Mother's with an IQ score at or above 85 are controls.

## A naive estimate of treatment effect:

```{r}
#naive treatment effect from RDD data
lm_naive = lm(sbiq48 ~ dc_trt, RDD.df)
summary(lm_naive)

```

Things to note here:

1. the original study was a randomized control experiment...so the average treatment effect of the interventions can be estimated without regard to selection into groups

2. our hypothetical example is more like an observational study where selection into groups is a concern

3. so the estimate above of 9.88 IQ points is a baseline against which our RDD estimates will evenutally be measured

## A McCrary test for continuity of assignment

The McCrary test was developed by [McCrary 2008](https://eml.berkeley.edu/~jmccrary/mccrary2006_DCdensity.pdf) and I have provided a .pdf copy of that paper.  The basic concern here is that if selection into the treatment group can be gamed, we will end up with lots of people (relative to expectations) who just barely qualify for the treatment group and few people (relative to expectations) who just barely don't qualify for the treatment.  Since the whole point of RDDs is to compare what happends to subject who are just below versus just above the treatment cutoffs, it would be bad to have subjects be able to 'game the system.'

The classic example here is the 'mercy pass' example.  Suppose students are assigned to summer school based on final grade.  If the teacher gives a 'mercy pass' to students who are very close to the cutoff we will end up a relatively high number of students just barely on the right side of the cutoff (those who do not receive the summer school treatment) and relatively few students on the left side of the cutoff (those who do receive the treatment).  If the students just on the right side of the cutoff are students for which the treatment would have been beneficial (because they were supposed to receive the treatment) then the RDD estimate of the impact of summer school on student performance will be baised.

```{r}
library(rdd)
#McCrary sorting test as implemented in RDD
rdd::DCdensity(RDD.sim$momwais0, median(RDD.df$momwais0), ext.out = TRUE)

```

The output of the McCrary test gives a statistical testing and a graphical illustration.  The null hypothesis of the McCrary test is of discontinuity in the distribution of assignment variable In this case it finds $z$=1.16 with $p$ = 0.244 indicating that we can reject the hypothesis of discontinuity.


## Placebo tests for local average treatment effects

Another important identifying assumption for RDDs is that the treatment effect only occurs at the cutoff.  We can use placebo tests from the [rddtools](https://cran.r-project.org/web/packages/rddtools/rddtools.pdf) package to test whether this assumption holds.

```{r}
library(rddtools)

#the rddtools package needs data to be loaded as an rdd_data object

dat_rddtools = rddtools::rdd_data(
  y = sbiq48,
  x = momwais0,
  data = RDD.sim,
  cutpoint = median(RDD.df$momwais0)
)

llm_rddtools = rddtools::rdd_reg_np(dat_rddtools)

rddtools::plotPlacebo(llm_rddtools,
                      same_bw = T,
                      from = .25,
                      to = .75)

```

Placebo tests basically ask the question, "what if we estimated the model with the wrong cutoff point."  The idea behind the placebo test is to do something you think is right (estimate the model with the correct cutoff point) then do a bunch of things you think are not right (estimate the model with different cutoff points).  If you get a significant estimate from a 'wrong model' then it strongly suggests that the results of your 'right model' cannot be trusted.

Here we see that for estimates of the local average treatment effect using a variety of other cutoff points are insignificant (the confidence intervals generally include 0).  But the LATE estimated at the correct cutoff point does appear significant.

## Estimation of the impact of early childhood intervention

Finally, we directly address the research question by estimating the treatment effect associated with early childhood intervention.

```{r}

# 
lm_rdd = rdd::RDestimate(sbiq48 ~ momwais0, RDD.sim,
                         cutpoint = median(RDD.df$momwais0))
summary(lm_rdd)

#plot of RDD as implemented in RDD
plot(lm_rdd)
```

The local average treatment effect is estimated here to be -9.085 and is statistically significant.  Recall that the reference estimate from the controlled experiment was about 9.8 so our LATE from RDD is pretty close.  The estimate from the rdd package is negative because Child's IQ at the cutoff drops.  This says that, at the cutoff, the IQ values for the treated groups are about 9 points higher than what we would expect to observe in the absence of the treatment.

### Quick note on cleaning up the default plot

The plot above is somewhat helpful but hard to change the defaults.  We can produce a similar plot using basic ggplot options and a Loess smoothing span of 1:

```{r}
ggplot(RDD.sim,aes(x=momwais0,y=sbiq48,group=dc_trt)) + geom_point() + 
  geom_smooth(method='loess', span=1) + theme_bw() + 
  xlab("Mother's IQ") + ylab("Child's IQ")


```

# Skills practice

### Lowess Smoothing

1. can you apply the Loess smoother to the data in *Lowes_practice.csv* and generate plots without the use of geom_smooth?  Try several different values for the span of the Loess filter and compare the plots.  

2.  Can you reproduce Figure 8 from Thoemmes, Liao, and Jin to address the sensativity of our point estimates to the chosen bandwidth?
